{
    "embedding_size": 128,
    "ffn_size": 512,
    "num_encoder_layers": 12,
    "num_decoder_layers": 12,
    "num_heads": 8,
    "attn_dropout_ratio": 0.2,
    "attn_weight_dropout_ratio": 0.2,
    "ffn_dropout_ratio": 0.2,
    "embedding_dropout_ratio":0.2,
    "learning_rate": 0.001,
    "warmup_steps": 1500,
    "beam_size": 5,
    "decoding_strategy": "greedy_search",
    "share_vocab":false,
    "symbol_for_tree":false,
    "max_len":128,
    "epoch_nums":100,
    "teacher_force_ratio":1.0,
    "add_sos":true,
    "add_eos":true,
    "equation_fix":"prefix"
}